{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformar timestamp em date e hour\n",
    "# Rodar o z-order com date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------------+---------+-------+-------------------+--------------------+----------+--------+\n",
      "|           latitude|          longitude|       tempo_captura|id_onibus|      c|                lt0|                 lt1|      data|    hora|\n",
      "+-------------------+-------------------+--------------------+---------+-------+-------------------+--------------------+----------+--------+\n",
      "|         -23.552871|-46.647738000000004|2024-01-31T01:39:09Z|    71212|609F-10|TERM. PRINC. ISABEL|       CHÁC. SANTANA|2024-01-31|01:39:09|\n",
      "|        -23.6532175| -46.74036099999999|2024-01-31T01:38:46Z|    71739|609F-10|TERM. PRINC. ISABEL|       CHÁC. SANTANA|2024-01-31|01:38:46|\n",
      "|        -23.6680755|         -46.748797|2024-01-31T01:38:37Z|    71361|609F-10|TERM. PRINC. ISABEL|       CHÁC. SANTANA|2024-01-31|01:38:37|\n",
      "|         -23.534974|        -46.6443435|2024-01-31T01:38:55Z|    71740|609F-10|TERM. PRINC. ISABEL|       CHÁC. SANTANA|2024-01-31|01:38:55|\n",
      "|        -23.6168605| -46.70167549999999|2024-01-31T01:38:36Z|    71839|609F-10|TERM. PRINC. ISABEL|       CHÁC. SANTANA|2024-01-31|01:38:36|\n",
      "|      -23.574599125|        -46.6680825|2024-01-31T01:38:47Z|    71844|609F-10|TERM. PRINC. ISABEL|       CHÁC. SANTANA|2024-01-31|01:38:47|\n",
      "|-23.668001500000003|        -46.7491535|2024-01-31T01:38:41Z|    71860|609F-10|TERM. PRINC. ISABEL|       CHÁC. SANTANA|2024-01-31|01:38:41|\n",
      "|         -23.541446|-46.536075499999995|2024-01-31T01:39:06Z|    48788|407I-10|      METRÔ BRESSER|CONJ. MANOEL DA N...|2024-01-31|01:39:06|\n",
      "|-23.549667499999998|-46.483762999999996|2024-01-31T01:38:43Z|    48985|407I-10|      METRÔ BRESSER|CONJ. MANOEL DA N...|2024-01-31|01:38:43|\n",
      "|        -23.5433355| -46.48539675000001|2024-01-31T01:38:46Z|    48445|407I-10|      METRÔ BRESSER|CONJ. MANOEL DA N...|2024-01-31|01:38:46|\n",
      "|        -23.5955305|           -46.6799|2024-01-31T01:39:01Z|    63370|576M-10|          PINHEIROS|           VL. CLARA|2024-01-31|01:39:01|\n",
      "|        -23.6368035|         -46.641181|2024-01-31T01:38:57Z|    63366|576M-10|          PINHEIROS|           VL. CLARA|2024-01-31|01:38:57|\n",
      "|-23.678067499999997|-46.640125499999996|2024-01-31T01:39:07Z|    63367|576M-10|          PINHEIROS|           VL. CLARA|2024-01-31|01:39:07|\n",
      "|         -23.565959|        -46.6944145|2024-01-31T01:38:32Z|    63369|576M-10|          PINHEIROS|           VL. CLARA|2024-01-31|01:38:32|\n",
      "|-23.678067499999997|-46.640125499999996|2024-01-31T01:39:08Z|    63344|576M-10|          PINHEIROS|           VL. CLARA|2024-01-31|01:39:08|\n",
      "|         -23.570103|         -46.486686|2024-01-31T01:38:36Z|    45676|3778-10|       METRÔ CARRÃO|  JD. STA. TEREZINHA|2024-01-31|01:38:36|\n",
      "|        -23.5753505|-46.497097499999995|2024-01-31T01:38:30Z|    45474|3778-10|       METRÔ CARRÃO|  JD. STA. TEREZINHA|2024-01-31|01:38:30|\n",
      "|         -23.570103|         -46.486686|2024-01-31T01:38:58Z|    45530|3778-10|       METRÔ CARRÃO|  JD. STA. TEREZINHA|2024-01-31|01:38:58|\n",
      "|-23.568366875000002|       -46.50955725|2024-01-31T01:39:13Z|    45327|3778-10|       METRÔ CARRÃO|  JD. STA. TEREZINHA|2024-01-31|01:39:13|\n",
      "|       -23.67216275|        -46.6441475|2024-01-31T01:38:45Z|    68258|5702-10|    METRÔ JABAQUARA|REFÚGIO STA. TERE...|2024-01-31|01:38:45|\n",
      "+-------------------+-------------------+--------------------+---------+-------+-------------------+--------------------+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "from delta import *\n",
    "from pyspark.sql.functions import split, to_date, hour, minute, second\n",
    "\n",
    "\n",
    "builder = SparkSession.builder.appName(\"topicos\").config(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\").config(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "INPUT_PATH = \"/home/felipe/code/teste_particionamento/dados/\"\n",
    "BRONZE_PATH = \"/home/felipe/code/teste_particionamento/lake/bronze/\"\n",
    "SILVER_PATH = \"/home/felipe/code/teste_particionamento/lake/silver/\"\n",
    "\n",
    "df = spark.read.format(\"parquet\").option(\"inferSchema\",\"true\").option(\"header\",\"true\").load(f\"{INPUT_PATH}/sp_micro/\")\n",
    "df = df.withColumn(\"data\", to_date(\"tempo_captura\")).withColumn(\"hora\", split(split(\"tempo_captura\", \"T\")[1], \"Z\")[0])\n",
    "\n",
    "df.show()\n",
    "\n",
    "\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/04 17:01:34 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "24/03/04 17:01:34 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 84,44% for 9 writers\n",
      "24/03/04 17:01:34 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 76,00% for 10 writers\n",
      "24/03/04 17:01:34 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 69,09% for 11 writers\n",
      "24/03/04 17:01:34 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 76,00% for 10 writers\n",
      "24/03/04 17:01:34 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 84,44% for 9 writers\n",
      "24/03/04 17:01:34 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "from delta import *\n",
    "from pyspark.sql.functions import split, to_date, hour, minute, second\n",
    "\n",
    "\n",
    "builder = SparkSession.builder.appName(\"topicos\").config(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\").config(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "INPUT_PATH = \"/home/felipe/code/teste_particionamento/dados/\"\n",
    "BRONZE_PATH = \"/home/felipe/code/teste_particionamento/lake/bronze\"\n",
    "SILVER_PATH = \"/home/felipe/code/teste_particionamento/lake/silver\"\n",
    "\n",
    "df = spark.read.format(\"parquet\").option(\"inferSchema\",\"true\").option(\"header\",\"true\").load(f\"{INPUT_PATH}/sp_micro/\")\n",
    "df = df.withColumn(\"data\", to_date(\"tempo_captura\")).withColumn(\"hora\", split(split(\"tempo_captura\", \"T\")[1], \"Z\")[0])\n",
    "\n",
    "df.write.mode(\"overwrite\").format(\"delta\").option(\"path\",f\"{BRONZE_PATH}/sp\").saveAsTable(\"bronze_sp2\")\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------------+---------+-------+--------------------+--------------------+----------+--------+\n",
      "|           latitude|          longitude|       tempo_captura|id_onibus|      c|                 lt0|                 lt1|      data|    hora|\n",
      "+-------------------+-------------------+--------------------+---------+-------+--------------------+--------------------+----------+--------+\n",
      "|       -23.51404925|-46.635337625000005|2024-02-10T05:53:46Z|    21706|179A-10|      PARQUE ANHEMBI|      TERMINAL TIETE|2024-02-10|05:53:46|\n",
      "|-23.614222499999997|         -46.678812|2024-02-10T05:52:41Z|    72518|N701-11|TERM. PQ. D. PEDR...|    TERM. STO. AMARO|2024-02-10|05:52:41|\n",
      "|         -23.489691|        -46.7170505|2024-02-10T05:54:57Z|    16540|N142-11|    TERM. CASA VERDE|      TERM. PIRITUBA|2024-02-10|05:54:57|\n",
      "|       -23.65097275|        -46.7572675|2024-02-10T05:54:16Z|    71203|6455-10|  LGO. SÃO FRANCISCO|     TERM. CAPELINHA|2024-02-10|05:54:16|\n",
      "|         -23.540153|         -46.483096|2024-02-10T05:53:37Z|    45092|2727-10|CONJ. A. E. CARVALHO|   METRÔ ARTUR ALVIM|2024-02-10|05:53:37|\n",
      "|-23.518318999999998|        -46.4758545|2024-02-10T05:53:32Z|    31628|1177-10|                 LUZ|TERM. A. E. CARVALHO|2024-02-10|05:53:32|\n",
      "|         -23.542434|         -46.471034|2024-02-10T05:55:22Z|    47235|3766-10|      METRÔ ITAQUERA|            COHAB II|2024-02-10|05:55:22|\n",
      "|-23.811533750000002|       -46.73621675|2024-02-10T05:56:16Z|    63056|6000-10|    TERM. STO. AMARO|   TERM. PARELHEIROS|2024-02-10|05:56:16|\n",
      "|      -23.735033875|      -46.694067875|2024-02-10T05:52:02Z|    66852|N635-11|        JD. GAIVOTAS|        TERM. GRAJAÚ|2024-02-10|05:52:02|\n",
      "|-23.731146000000003|-46.785866999999996|2024-02-10T05:56:04Z|    73926|6840-10|     TERM. CAPELINHA|    TERM. JD. JACIRA|2024-02-10|05:56:04|\n",
      "|        -23.5894755|         -46.633868|2024-02-10T05:56:29Z|    51096|4709-10|   METRÔ VL. MARIANA|     JD. SÃO SAVÉRIO|2024-02-10|05:56:29|\n",
      "|        -23.5058355|-46.673193999999995|2024-02-10T05:56:11Z|    21301|N205-11|     TERM. PINHEIROS|  TERM. CACHOEIRINHA|2024-02-10|05:56:11|\n",
      "|        -23.5476865|        -46.6292585|2024-02-10T05:56:49Z|    31303|208V-10|TERM. PQ. D. PEDR...|TERM. A. E. CARVALHO|2024-02-10|05:56:49|\n",
      "|         -23.539874|         -46.516463|2024-02-10T05:53:37Z|    45397|3731-10|   METRÔ VL. MATILDE|    SHOP. ARICANDUVA|2024-02-10|05:53:37|\n",
      "|         -23.653551|         -46.777357|2024-02-10T05:53:52Z|    72942|7060-10|   TERM. CAMPO LIMPO|          VALO VELHO|2024-02-10|05:53:52|\n",
      "|        -23.7374635|         -46.697805|2024-02-10T05:52:04Z|    61349|5630-10|          METRÔ BRÁS|        TERM. GRAJAÚ|2024-02-10|05:52:04|\n",
      "|        -23.5725605|         -46.704529|2024-02-10T05:56:52Z|    81604|N801-11|TERM. PQ. D. PEDR...|       METRÔ BUTANTÃ|2024-02-10|05:56:52|\n",
      "|         -23.544384|         -46.389341|2024-02-10T05:56:33Z|    36292|2021-10|     CPTM GUAIANASES|    JD. BANDEIRANTES|2024-02-10|05:56:33|\n",
      "|         -23.767591|        -46.7163045|2024-02-10T05:53:01Z|    66902|6072-23|      BALN. SÃO JOSÉ|      TERM. VARGINHA|2024-02-10|05:53:01|\n",
      "|         -23.558473|-46.523022499999996|2024-02-10T05:56:42Z|    41013|N405-11|      METRÔ ITAQUERA|    TERM. VL. CARRÃO|2024-02-10|05:56:42|\n",
      "+-------------------+-------------------+--------------------+---------+-------+--------------------+--------------------+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "from delta import *\n",
    "from pyspark.sql.functions import split, to_date, hour, minute, second, col\n",
    "\n",
    "\n",
    "builder = SparkSession.builder.appName(\"topicos\").config(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\").config(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "INPUT_PATH = \"/home/felipe/code/teste_particionamento/dados/\"\n",
    "BRONZE_PATH = \"/home/felipe/code/teste_particionamento/lake/bronze\"\n",
    "SILVER_PATH = \"/home/felipe/code/teste_particionamento/lake/silver\"\n",
    "\n",
    "df = spark.read.format(\"delta\").load(f\"{BRONZE_PATH}/sp/\")\n",
    "df.show()\n",
    "\n",
    "\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|           latitude|          longitude|\n",
      "+-------------------+-------------------+\n",
      "|         -23.552871|-46.647738000000004|\n",
      "|        -23.6532175| -46.74036099999999|\n",
      "|        -23.6680755|         -46.748797|\n",
      "|         -23.534974|        -46.6443435|\n",
      "|        -23.6168605| -46.70167549999999|\n",
      "|      -23.574599125|        -46.6680825|\n",
      "|-23.668001500000003|        -46.7491535|\n",
      "|         -23.541446|-46.536075499999995|\n",
      "|-23.549667499999998|-46.483762999999996|\n",
      "|        -23.5433355| -46.48539675000001|\n",
      "|        -23.5955305|           -46.6799|\n",
      "|        -23.6368035|         -46.641181|\n",
      "|-23.678067499999997|-46.640125499999996|\n",
      "|         -23.565959|        -46.6944145|\n",
      "|-23.678067499999997|-46.640125499999996|\n",
      "|         -23.570103|         -46.486686|\n",
      "|        -23.5753505|-46.497097499999995|\n",
      "|         -23.570103|         -46.486686|\n",
      "|-23.568366875000002|       -46.50955725|\n",
      "|       -23.67216275|        -46.6441475|\n",
      "+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "from delta import *\n",
    "from pyspark.sql.functions import split, to_date, hour, minute, second, col\n",
    "\n",
    "\n",
    "builder = SparkSession.builder.appName(\"topicos\").config(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\").config(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "INPUT_PATH = \"/home/felipe/code/teste_particionamento/dados/\"\n",
    "BRONZE_PATH = \"/home/felipe/code/teste_particionamento/lake/bronze\"\n",
    "SILVER_PATH = \"/home/felipe/code/teste_particionamento/lake/silver\"\n",
    "\n",
    "df = spark.read.format(\"delta\").load(f\"{BRONZE_PATH}/sp/\")\n",
    "df_filtrado = df.filter(df.data==\"2024-01-31\").select(\"latitude\",\"longitude\")\n",
    "df_filtrado.show()\n",
    "\n",
    "\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/05 10:20:08 WARN Utils: Your hostname, desktop resolves to a loopback address: 127.0.1.1; using 192.168.0.104 instead (on interface enp6s0)\n",
      "24/03/05 10:20:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/felipe/.local/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/felipe/.ivy2/cache\n",
      "The jars for the packages stored in: /home/felipe/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-979d5ae8-5874-43c5-a7d5-65c6acee9187;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.1.0 in central\n",
      "\tfound io.delta#delta-storage;3.1.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 108ms :: artifacts dl 4ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.12;3.1.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.1.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-979d5ae8-5874-43c5-a7d5-65c6acee9187\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/3ms)\n",
      "24/03/05 10:20:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/05 10:20:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "from delta import *\n",
    "from pyspark.sql.functions import split, to_date, hour, minute, second, col\n",
    "\n",
    "\n",
    "builder = SparkSession.builder.appName(\"topicos\").config(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\").config(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "INPUT_PATH = \"/home/felipe/code/teste_particionamento/dados/\"\n",
    "BRONZE_PATH = \"/home/felipe/code/teste_particionamento/lake/bronze\"\n",
    "SILVER_PATH = \"/home/felipe/code/teste_particionamento/lake/silver\"\n",
    "\n",
    "deltaTable = DeltaTable.forPath(spark,f\"{BRONZE_PATH}/sp/\").optimize().executeZOrderBy(\"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark.read.format(\"delta\").load(f\"{BRONZE_PATH}/sp/\").createOrReplaceTempView(\"teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.14 ms, sys: 299 µs, total: 1.44 ms\n",
      "Wall time: 12.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[latitude: double, longitude: double]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "spark.sql(\"select latitude, longitude from teste where data = '2024-02-13'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    spark.read.format(\"delta\")\n",
    "    .option(\"versionAsOf\", \"3\")\n",
    "    .load(f\"{BRONZE_PATH}/sp/\")\n",
    "    .createOrReplaceTempView(\"v0\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 876 µs, sys: 530 µs, total: 1.41 ms\n",
      "Wall time: 7.62 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[latitude: double, longitude: double]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "spark.sql(\n",
    "    \"select latitude,longitude from v0 where data = '2024-02-10'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_files_<1mb': 10,\n",
       " 'num_files_1mb-500mb': 0,\n",
       " 'num_files_500mb-1gb': 0,\n",
       " 'num_files_1gb-2gb': 0,\n",
       " 'num_files_>2gb': 0}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import levi\n",
    "import deltalake\n",
    "\n",
    "dt = deltalake.DeltaTable(f\"{BRONZE_PATH}/sp/\", version=0)\n",
    "levi.delta_file_sizes(dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_files_<1mb': 0,\n",
       " 'num_files_1mb-500mb': 1,\n",
       " 'num_files_500mb-1gb': 0,\n",
       " 'num_files_1gb-2gb': 0,\n",
       " 'num_files_>2gb': 0}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = deltalake.DeltaTable(f\"{BRONZE_PATH}/sp/\", version=4)\n",
    "levi.delta_file_sizes(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 2.74 ms, total: 2.74 ms\n",
      "Wall time: 231 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(latitude=-23.536727, longitude=-46.4727215),\n",
       " Row(latitude=-23.5365385, longitude=-46.473466),\n",
       " Row(latitude=-23.537959999999998, longitude=-46.4775645),\n",
       " Row(latitude=-23.540062499999998, longitude=-46.482594375),\n",
       " Row(latitude=-23.539995499999996, longitude=-46.482319125),\n",
       " Row(latitude=-23.521487999999998, longitude=-46.4604785),\n",
       " Row(latitude=-23.524583874999998, longitude=-46.460325375000004),\n",
       " Row(latitude=-23.524997, longitude=-46.462630000000004),\n",
       " Row(latitude=-23.5216453125, longitude=-46.45799975),\n",
       " Row(latitude=-23.52415275, longitude=-46.461254),\n",
       " Row(latitude=-23.526246, longitude=-46.464134),\n",
       " Row(latitude=-23.523037000000002, longitude=-46.46134825),\n",
       " Row(latitude=-23.527046, longitude=-46.459491),\n",
       " Row(latitude=-23.521929, longitude=-46.4574135),\n",
       " Row(latitude=-23.530592, longitude=-46.466698),\n",
       " Row(latitude=-23.5235395, longitude=-46.4615515),\n",
       " Row(latitude=-23.53313875, longitude=-46.466909875),\n",
       " Row(latitude=-23.5322585, longitude=-46.46684675),\n",
       " Row(latitude=-23.528943374999997, longitude=-46.46580125),\n",
       " Row(latitude=-23.526575, longitude=-46.464445),\n",
       " Row(latitude=-23.5260305, longitude=-46.46393),\n",
       " Row(latitude=-23.527868812500003, longitude=-46.4618689375),\n",
       " Row(latitude=-23.528337, longitude=-46.460350000000005),\n",
       " Row(latitude=-23.540153, longitude=-46.483096),\n",
       " Row(latitude=-23.540153, longitude=-46.483096),\n",
       " Row(latitude=-23.540153, longitude=-46.483096),\n",
       " Row(latitude=-23.540153, longitude=-46.483096),\n",
       " Row(latitude=-23.540153, longitude=-46.483096),\n",
       " Row(latitude=-23.540153, longitude=-46.483096),\n",
       " Row(latitude=-23.540153, longitude=-46.483096)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "%%time\n",
    "\n",
    "spark.sql(\n",
    "    \"select latitude,longitude from v0 where id_onibus = '45092'\"\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from delta import *\n",
    "from pyspark.sql.functions import split, to_date, hour, minute, second, col\n",
    "\n",
    "\n",
    "builder = SparkSession.builder.appName(\"topicos\").config(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\").config(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "INPUT_PATH = \"/home/felipe/code/teste_particionamento/dados/\"\n",
    "BRONZE_PATH = \"/home/felipe/code/teste_particionamento/lake/bronze\"\n",
    "SILVER_PATH = \"/home/felipe/code/teste_particionamento/lake/silver\"\n",
    "\n",
    "deltaTable = DeltaTable.forPath(spark,f\"{BRONZE_PATH}/sp/\").optimize().executeZOrderBy(\"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    spark.read.format(\"delta\")\n",
    "    .option(\"versionAsOf\", \"5\")\n",
    "    .load(f\"{BRONZE_PATH}/sp/\")\n",
    "    .createOrReplaceTempView(\"v5\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.32 ms, sys: 588 µs, total: 2.91 ms\n",
      "Wall time: 210 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(latitude=-23.5266425, longitude=-46.66785350000001),\n",
       " Row(latitude=-23.462593499999997, longitude=-46.6814735),\n",
       " Row(latitude=-23.528945, longitude=-46.676366),\n",
       " Row(latitude=-23.526874, longitude=-46.673227),\n",
       " Row(latitude=-23.5265825, longitude=-46.6727935),\n",
       " Row(latitude=-23.5258435, longitude=-46.6698235),\n",
       " Row(latitude=-23.518002375000002, longitude=-46.699468625)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "%%time\n",
    "\n",
    "spark.sql(\n",
    "    \"select latitude,longitude from v5 where id_onibus = '16090'\"\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_files': 1, 'num_files_skipped': 0, 'num_bytes_skipped': 0}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = deltalake.DeltaTable(f\"{BRONZE_PATH}/sp/\", version=5)\n",
    "levi.delta_file_sizes(dt)\n",
    "levi.skipped_stats(dt, filters=[(\"id_onibus\", \"=\", \"16090\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_files': 10, 'num_files_skipped': 0, 'num_bytes_skipped': 0}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = deltalake.DeltaTable(f\"{BRONZE_PATH}/sp/\", version=0)\n",
    "levi.delta_file_sizes(dt)\n",
    "levi.skipped_stats(dt, filters=[(\"id_onibus\", \"=\", \"16090\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.56 ms, sys: 120 µs, total: 1.68 ms\n",
      "Wall time: 10 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[latitude: double, longitude: double]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "spark.sql(\"select latitude, longitude from v0 where data = '2024-02-13'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
